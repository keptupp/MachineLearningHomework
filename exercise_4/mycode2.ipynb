{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络的多分类问题（第一版还是用不了）  \n",
    "重写一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from scipy.io import loadmat#读取mat文件\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+numpy.exp(-z))\n",
    "\n",
    "def Dsigmoid(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def getData():\n",
    "    data=loadmat(\"ex4data1.mat\")\n",
    "    x=numpy.insert(data['X'],0,numpy.ones((5000)),axis=1)\n",
    "    y=numpy.array(data['y'])\n",
    "    ynum=numpy.array(data['y'])\n",
    "    y=numpy.zeros((x.shape[0],10))\n",
    "    for i in range(len(ynum)):\n",
    "        y[i][ynum[i]-1]=1\n",
    "    # theta1=(numpy.random.random((25,x.shape[1]))-0.5)*0.25\n",
    "    # theta2=(numpy.random.random((10,26))-0.5)*0.25\n",
    "    theta1=numpy.array(numpy.load('theta12.npy'))\n",
    "    theta2=numpy.array(numpy.load('theta22.npy'))\n",
    "\n",
    "\n",
    "    return x,y,theta1,theta2\n",
    "\n",
    "def propagate_forward(x,theta1,theta2):\n",
    "    z1=x@theta1.T\n",
    "    h1=sigmoid(z1)\n",
    "    h1=numpy.insert(h1,0,numpy.ones((5000)),axis=1)\n",
    "    z2=h1@theta2.T\n",
    "    h2=sigmoid(z2)\n",
    "    return h2,h1\n",
    "\n",
    "def cost(y,h2,theta1,theta2,L):\n",
    "    m=y.shape[0]\n",
    "    price=(-y*numpy.log(h2)-(1-y)*numpy.log(1-h2)).sum()/m\n",
    "    regularization=(numpy.power(theta1,2).sum()+numpy.power(theta2,2).sum())*L/(2*m)\n",
    "    return price+regularization\n",
    "\n",
    "def back_propagation(theta1,theta2,x,errorValue,h1,dh1):\n",
    "    decline2=numpy.zeros((10,26))\n",
    "    decline1=numpy.zeros((25,401))\n",
    "\n",
    "    for i in range(5000):\n",
    "        decline2=decline2+errorValue[i].reshape(-1,1) @ h1[i].reshape(-1,1).T\n",
    "\n",
    "        a=errorValue[i].reshape(-1,1).T@theta2\n",
    "        b=dh1[i].reshape(-1,1)@x[i].reshape(-1,1).T\n",
    "\n",
    "        decline1=decline1+a[:,1:].T*b\n",
    "\n",
    "    return decline1,decline2\n",
    "\n",
    "def neural_networks():\n",
    "    x,y,theta1,theta2=getData()\n",
    "    costs=[]\n",
    "    for i in range(50):\n",
    "        h2,h1=propagate_forward(x,theta1,theta2)\n",
    "        j=cost(y,h2,theta1,theta2,1)\n",
    "        errorValue=h2-y\n",
    "        dh1=Dsigmoid(x@theta1.T)\n",
    "        decline1,decline2=back_propagation(theta1,theta2,x,errorValue,h1,dh1)\n",
    "        theta1=theta1-0.00001*decline1\n",
    "        theta2=theta2-0.00001*decline2\n",
    "        costs.append(j)\n",
    "    plt.plot(costs)\n",
    "    numpy.save('theta12.npy',theta1)\n",
    "    numpy.save(\"theta22.npy\",theta2)\n",
    "    print(j)\n",
    "\n",
    "#neural_networks()\n",
    "\n",
    "def test():\n",
    "    x,y,theta1,theta2=getData()\n",
    "    h2,h1=propagate_forward(x,theta1,theta2)\n",
    "    h2[h2>0.5]=1\n",
    "    h2[h2<=0.5]=0\n",
    "    rigth=0\n",
    "    for i in range(5000):\n",
    "        if (h2[i,:]==y[i,:]).sum()==10:\n",
    "            rigth+=1\n",
    "    print(rigth,rigth/5000)\n",
    "test()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1daca1ebfa99d363f49187de6dd878fa6001e85bc2f160c60bcd81d0df0caa1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
